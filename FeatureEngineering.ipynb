{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehashukla91/-Python---Data-Structure/blob/main/Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is a parameter?\n",
        "\n",
        "ANS-> In various contexts, a parameter can have slightly different meanings:\n",
        "\n",
        "1. Programming: In programming, a parameter is a variable or value passed to a function, procedure, or method to influence its behavior or provide input. Parameters are typically defined in the function signature and are used to customize the function's output.\n",
        "\n",
        "Example: def greet(name, age): print(f\"Hello, {name}! You are {age} years old.\")\n",
        "\n",
        "In this example, name and age are parameters.\n",
        "\n",
        "1. Mathematics: In mathematics, a parameter is a constant or variable used to define a family of functions, curves, or shapes.\n",
        "\n",
        "Example: The equation y = ax^2 + bx + c has parameters a, b, and c.\n",
        "\n",
        "1. Statistics: In statistics, a parameter is a numerical value describing a population characteristic, such as mean, variance, or standard deviation.\n",
        "\n",
        "Example: The population mean (μ) is a parameter.\n",
        "\n",
        "1. General usage: In general, a parameter can refer to any measurable or adjustable factor influencing a system, process, or outcome.\n",
        "\n",
        "Example: Temperature, pressure, and pH are parameters affecting chemical reactions."
      ],
      "metadata": {
        "id": "aHZRYh51edFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is correlation?\n",
        "What does negative correlation mean?\n",
        "\n",
        "ANS-> Correlation measures the strength and direction of the linear relationship between two continuous variables. It ranges from -1 (perfect negative correlation) to 1 (perfect positive correlation), with 0 indicating no correlation.\n",
        "\n",
        "Types of Correlation\n",
        "\n",
        "1. Positive Correlation (0 < r < 1): As one variable increases, the other variable tends to increase.\n",
        "Example: Income and spending.\n",
        "\n",
        "2. Negative Correlation (-1 < r < 0): As one variable increases, the other variable tends to decrease.\n",
        "Example: Temperature and ice cream sales.\n",
        "\n",
        "3. No Correlation (r ≈ 0): No linear relationship exists.\n",
        "Example: Height and favorite color.\n",
        "\n",
        "Negative Correlation\n",
        "\n",
        "Negative correlation indicates that:\n",
        "\n",
        "1. As Variable A increases, Variable B tends to decrease.\n",
        "2. As Variable A decreases, Variable B tends to increase.\n",
        "\n",
        "Examples:\n",
        "\n",
        "1. Stock prices and bond yields: When stock prices rise, bond yields tend to fall.\n",
        "2. Temperature and heating costs: Higher temperatures lead to lower heating costs.\n",
        "3. Exercise frequency and body fat percentage: More exercise tends to reduce body fat.\n",
        "\n",
        "Key Points\n",
        "\n",
        "1. Correlation does not imply causation.\n",
        "2. Correlation is sensitive to data outliers and non-linear relationships.\n",
        "3. Correlation coefficient (r) measures strength and direction.\n",
        "\n",
        "Common correlation coefficients:\n",
        "\n",
        "1. Pearson's r (linear correlation)\n",
        "2. Spearman's ρ (rank correlation)\n",
        "3. Kendall's τ (non-parametric correlation)"
      ],
      "metadata": {
        "id": "XBWvjHTrenD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "ANS-> Definition of Machine Learning\n",
        "\n",
        "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables systems to learn from data, identify patterns, and make predictions or decisions without explicit programming.\n",
        "\n",
        "Main Components of Machine Learning\n",
        "\n",
        "1. Data: The foundation of ML, data is used to train and test models.\n",
        "2. Algorithms: Mathematical formulas and statistical techniques used to analyze data.\n",
        "3. Models: Representations of relationships between data inputs and outputs.\n",
        "4. Features: Relevant variables extracted from data to inform model decisions.\n",
        "5. Target Variable: The outcome or response variable models aim to predict.\n",
        "6. Training: Process of teaching models using labeled data.\n",
        "7. Testing: Evaluating model performance on unseen data.\n",
        "8. Evaluation Metrics: Measures assessing model accuracy, precision, recall, F1 score, etc.\n",
        "9. Hyperparameters: Adjustable parameters controlling model complexity.\n"
      ],
      "metadata": {
        "id": "l9bmREm4e8OU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "ANS-> Loss value, also known as cost function or objective function, measures the difference between a machine learning model's predictions and actual outcomes. It helps evaluate model performance and determine whether the model is good or not.\n",
        "\n",
        "Loss Value Purposes\n",
        "\n",
        "1. Model Evaluation: Loss value assesses model accuracy.\n",
        "2. Model Comparison: Compare performance across models.\n",
        "3. Hyperparameter Tuning: Optimize hyperparameters.\n",
        "4. Model Improvement: Identify areas for improvement.\n",
        "\n",
        "Common Loss Functions\n",
        "\n",
        "1. Mean Squared Error (MSE)\n",
        "2. Mean Absolute Error (MAE)\n",
        "3. Cross-Entropy Loss\n",
        "4. Binary Cross-Entropy Loss\n",
        "\n",
        "Interpreting Loss Value\n",
        "\n",
        "1. Lower Loss: Better model performance.\n",
        "2. Higher Loss: Poorer model performance.\n",
        "3. Converging Loss: Model learning.\n",
        "4. Plateauing Loss: Model convergence.\n",
        "\n",
        "Good Model Indicators\n",
        "\n",
        "1. Low loss value\n",
        "2. Decreasing loss over iterations\n",
        "3. High accuracy\n",
        "4. Precise predictions\n",
        "\n",
        "Bad Model Indicators\n",
        "\n",
        "1. High loss value\n",
        "2. Increasing loss over iterations\n",
        "3. Low accuracy\n",
        "4. Large prediction errors\n",
        "\n",
        "Additional Metrics\n",
        "\n",
        "1. Accuracy\n",
        "2. Precision\n",
        "3. Recall\n",
        "4. F1 Score\n",
        "5. ROC-AUC"
      ],
      "metadata": {
        "id": "HRs5ujlYfPAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What are continuous and categorical variables?\n",
        "\n",
        "ANS-> In statistics and data science, variables are classified into two primary types: continuous and categorical.\n",
        "Continuous Variables\n",
        "1. Definition: Variables that can take any value within a range or interval.\n",
        "2. Characteristics:\n",
        "    1. Quantitative\n",
        "    2. Measurable\n",
        "    3. Can be expressed as decimals or fractions\n",
        "    4. Have no natural categories\n",
        "3. Examples:\n",
        "    1. Height (inches or centimeters)\n",
        "    2. Weight (pounds or kilograms)\n",
        "    3. Temperature (degrees Fahrenheit or Celsius)\n",
        "    4. Age (years)\n",
        "    5. Income (dollars)\n",
        "Categorical Variables\n",
        "4. Definition: Variables that represent distinct categories or groups.\n",
        "5. Characteristics:\n",
        "    1. Qualitative\n",
        "    2. Non-numerical\n",
        "    3. Divided into discrete categories\n",
        "    4. No inherent order\n",
        "6. Examples:\n",
        "    1. Gender (Male, Female, Other)\n",
        "    2. Color (Red, Blue, Green)\n",
        "    3. Occupation (Student, Engineer, Doctor)\n",
        "    4. Marital Status (Single, Married, Divorced)\n",
        "    5. Product Category (Electronics, Clothing, Home Goods)"
      ],
      "metadata": {
        "id": "3z06K-8YfekG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "ANS-> Handling categorical variables is crucial in machine learning. Here are common techniques:\n",
        "\n",
        "Common Techniques\n",
        "\n",
        "1. One-Hot Encoding (OHE)\n",
        "1. Convert categorical variables into binary vectors.\n",
        "2. Example: Color (Red, Green, Blue) becomes:\n",
        "    1. Red: [1, 0, 0]\n",
        "    2. Green: [0, 1, 0]\n",
        "    3. Blue: [0, 0, 1]\n",
        "\n",
        "2. Label Encoding\n",
        "1. Assign numerical values to categories.\n",
        "2. Example: Color (Red, Green, Blue) becomes:\n",
        "    1. Red: 0\n",
        "    2. Green: 1\n",
        "    3. Blue: 2\n",
        "\n",
        "3. Ordinal Encoding\n",
        "1. Assign ordered numerical values.\n",
        "2. Example: Education Level (High School, Bachelor's, Master's) becomes:\n",
        "    1. High School: 1\n",
        "    2. Bachelor's: 2\n",
        "    3. Master's: 3\n",
        "\n",
        "Additional Techniques\n",
        "\n",
        "4. Hashing\n",
        "1. Map categories to numerical values using hash functions.\n",
        "2. Example: Color (Red, Green, Blue) becomes:\n",
        "    1. Red: 123\n",
        "    2. Green: 456\n",
        "    3. Blue: 789\n",
        "\n",
        "5. Frequency Encoding\n",
        "1. Replace categories with frequency counts.\n",
        "2. Example: Color (Red, Green, Blue) becomes:\n",
        "    1. Red: 0.5 (50% frequency)\n",
        "    2. Green: 0.3 (30% frequency)\n",
        "    3. Blue: 0.2 (20% frequency)\n",
        "\n",
        "6. Mean Encoding\n",
        "1. Replace categories with mean target variable values.\n",
        "2. Example: Color (Red, Green, Blue) becomes:\n",
        "    1. Red: 10.5 (mean target value)\n",
        "    2. Green: 20.3\n",
        "    3. Blue: 15.2\n",
        "\n",
        "7. Embeddings\n",
        "1. Learn dense vector representations.\n",
        "2. Example: Word2Vec, GloVe\n",
        "\n",
        "Considerations\n",
        "\n",
        "1. Handle Missing Values\n",
        "1. Impute or remove missing categorical values.\n",
        "\n",
        "2. Avoid Overfitting\n",
        "1. Regularization techniques (e.g., L1, L2).\n",
        "2. Dimensionality reduction.\n",
        "\n",
        "3. Choose Suitable Technique\n",
        "1. Consider data size, complexity, and model type.\n",
        "\n",
        "4. Validate Results\n",
        "1. Monitor performance metrics."
      ],
      "metadata": {
        "id": "E1OZpfOyf6tY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. What do you mean by training and testing a dataset?\n",
        "\n",
        "ANS-> In machine learning, training and testing datasets are crucial components of the model development process.\n",
        "\n",
        "Training Dataset\n",
        "1. Purpose: Teach the model to learn patterns and relationships.\n",
        "2. Composition: Labeled data (input and expected output).\n",
        "3. Size: Typically 70-80% of the total dataset.\n",
        "4. Use: Model learns from training data to optimize weights and biases.\n",
        "\n",
        "Testing Dataset\n",
        "5. Purpose: Evaluate model performance and generalization.\n",
        "6. Composition: Unseen, labeled data (input and expected output).\n",
        "7. Size: Typically 20-30% of the total dataset.\n",
        "8. Use: Assess model accuracy, precision, recall, and F1 score."
      ],
      "metadata": {
        "id": "emuO2SQVgLzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8.What is sklearn.preprocessing?\n",
        "\n",
        "ANS-> sklearn.preprocessing is a module in scikit-learn, providing various techniques for data preprocessing, transformation, and feature engineering. Its primary goal is to prepare data for machine learning algorithms.\n",
        "\n",
        "Key functionalities:\n",
        "\n",
        "1. Data scaling and normalization\n",
        "2. Encoding categorical variables\n",
        "3. Handling missing values\n",
        "4. Feature transformation (e.g., polynomial, log)\n",
        "5. Data normalization (e.g., L1, L2)\n",
        "6. Text processing (tokenization, stopword removal)\n",
        "\n",
        "Commonly used classes and functions:\n",
        "\n",
        "1. StandardScaler\n",
        "2. MinMaxScaler\n",
        "3. OneHotEncoder\n",
        "4. LabelEncoder\n",
        "5. Imputer\n",
        "6. PolynomialFeatures\n",
        "7. TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "\n",
        "Benefits:\n",
        "\n",
        "1. Simplifies data preparation\n",
        "2. Improves model performance\n",
        "3. Enhances data quality\n",
        "4. Supports various data types\n",
        "5. Integrates well with scikit-learn algorithms\n",
        "\n",
        "Example usage:\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Create a StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "transformed_data = scaler.fit_transform(data)\n",
        "\n",
        "print(transformed_data)"
      ],
      "metadata": {
        "id": "rLdr0htmgoQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is a Test set?\n",
        "\n",
        "ANS-> In machine learning, a test set (also known as a testing set or evaluation set) is a portion of a dataset used to evaluate the performance of a trained model on unseen data.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "1. Unseen data: Not used during training.\n",
        "2. Representative: Reflects the same distribution as the training data.\n",
        "3. Labeled: Contains expected outputs.\n",
        "\n",
        "Purpose:\n",
        "\n",
        "1. Evaluate model performance.\n",
        "2. Estimate generalization error.\n",
        "3. Compare models.\n",
        "4. Tune hyperparameters.\n",
        "5. Detect overfitting.\n",
        "\n",
        "Typical usage:\n",
        "\n",
        "1. Split dataset into training (70-80%), validation (10-15%), and test sets (10-15%).\n",
        "2. Train model on training data.\n",
        "3. Fine-tune hyperparameters using validation set.\n",
        "4. Evaluate final model on test set.\n",
        "\n",
        "Benefits:\n",
        "\n",
        "1. Accurate performance estimation.\n",
        "2. Prevents overfitting.\n",
        "3. Ensures generalization.\n",
        "4. Comparability across models.\n",
        "\n",
        "Best practices:\n",
        "\n",
        "1. Random sampling.\n",
        "2. Stratified sampling (maintain class balance).\n",
        "3. Cross-validation (k-fold).\n",
        "4. Avoid data leakage.\n",
        "\n",
        "Example:\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model on training data\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test data\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "41AKPlD9g1Ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "ANS-> Splitting Data in Python:\n",
        "\n",
        "You can split data using Scikit-learn's train_test_split function:\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "Common Splitting Ratios:\n",
        "\n",
        "1. 70% training, 30% testing\n",
        "2. 80% training, 20% testing\n",
        "3. k-fold cross-validation\n",
        "\n",
        "Approaching a Machine Learning Problem:\n",
        "\n",
        "1. Problem Definition: Identify the problem, goals, and key performance indicators (KPIs).\n",
        "2. Data Collection: Gather relevant data from various sources.\n",
        "3. Data Preprocessing:\n",
        "    1. Handle missing values.\n",
        "    2. Remove duplicates.\n",
        "    3. Encode categorical variables.\n",
        "    4. Scale/normalize data.\n",
        "4. Exploratory Data Analysis (EDA):\n",
        "    1. Visualize data distributions.\n",
        "    2. Analyze correlations.\n",
        "    3. Identify outliers.\n",
        "5. Model Selection: Choose suitable algorithms based on problem type and data characteristics.\n",
        "6. Model Training: Split data, train models, and hyperparameter tuning.\n",
        "7. Model Evaluation: Assess performance using metrics (accuracy, precision, recall, F1 score).\n",
        "8. Model Deployment: Integrate trained models into applications.\n",
        "9. Continuous Monitoring and Improvement: Refine models based on feedback and new data.\n",
        "\n",
        "Machine Learning Workflow Tools:\n",
        "\n",
        "1. Jupyter Notebook\n",
        "2. Google Colab\n",
        "3. Scikit-learn\n",
        "4. TensorFlow\n",
        "5. PyTorch\n",
        "6. Pandas\n",
        "7. NumPy\n",
        "8. Matplotlib\n",
        "9. Seaborn\n",
        "\n",
        "Example Code:\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "U5V9ewBxhJz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "ANS-> Performing Exploratory Data Analysis (EDA) before fitting a model is crucial for several reasons:\n",
        "\n",
        "1. Understanding Data Distribution: EDA helps visualize data distributions, identifying patterns, outliers, and anomalies.\n",
        "2. Identifying Relationships: EDA reveals correlations, interactions, and relationships between variables.\n",
        "3. Detecting Missing Values: EDA identifies missing data, enabling appropriate handling.\n",
        "4. Data Quality Checks: EDA detects errors, inconsistencies, and inconsistencies.\n",
        "5. Feature Engineering: EDA informs feature creation, transformation, and selection.\n",
        "6. Model Selection: EDA guides choice of suitable models based on data characteristics.\n",
        "7. Hyperparameter Tuning: EDA provides insights for hyperparameter initialization.\n",
        "8. Avoiding Assumptions: EDA challenges assumptions, ensuring more informed modeling.\n",
        "9. Improving Model Performance: EDA optimizes feature space, leading to better results.\n",
        "10. Reducing Modeling Time: EDA streamlines modeling process by identifying key factors.\n",
        "\n",
        "Common EDA Techniques:\n",
        "\n",
        "1. Summary statistics (mean, median, std)\n",
        "2. Data visualization (histograms, scatter plots, box plots)\n",
        "3. Correlation analysis (heatmaps, pair plots)\n",
        "4. Missing value analysis\n",
        "5. Outlier detection\n",
        "\n",
        "Tools for EDA:\n",
        "\n",
        "1. Pandas\n",
        "2. NumPy\n",
        "3. Matplotlib\n",
        "4. Seaborn\n",
        "5. Plotly\n",
        "6. Scikit-learn\n",
        "\n",
        "Example EDA Code:\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "# Histograms\n",
        "df.hist(figsize=(10, 6))\n",
        "\n",
        "# Correlation heatmap\n",
        "sns.heatmap(df.corr(), annot=True)\n",
        "\n",
        "# Scatter plot\n",
        "sns.scatterplot(x='feature1', y='feature2', data=df)"
      ],
      "metadata": {
        "id": "n4kIir-xh82o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. What is correlation?\n",
        "\n",
        "ANS-> Correlation measures the strength and direction of the linear relationship between two continuous variables.\n",
        "\n",
        "Types of Correlation:\n",
        "\n",
        "1. Positive Correlation (0  r  1): As one variable increases, the other variable tends to increase.\n",
        "Example: Income and spending.\n",
        "\n",
        "2. Negative Correlation (-1  r  0): As one variable increases, the other variable tends to decrease.\n",
        "Example: Temperature and ice cream sales.\n",
        "\n",
        "3. No Correlation (r ≈ 0): No linear relationship exists.\n",
        "Example: Height and favorite color.\n",
        "\n",
        "Correlation Coefficient (r):\n",
        "\n",
        "1. Measures strength and direction.\n",
        "2. Ranges from -1 (perfect negative) to 1 (perfect positive).\n",
        "3. Interpretation:\n",
        "    1. 0.7-1: Strong positive.\n",
        "    2. 0.3-0.69: Moderate positive.\n",
        "    3. 0.1-0.29: Weak positive.\n",
        "    4. -0.1--0.29: Weak negative.\n",
        "    5. -0.3--0.69: Moderate negative.\n",
        "    6. -0.7--1: Strong negative.\n",
        "\n",
        "Common Correlation Coefficients:\n",
        "\n",
        "1. Pearson's r (linear correlation).\n",
        "2. Spearman's ρ (rank correlation).\n",
        "3. Kendall's τ (non-parametric correlation).\n",
        "\n",
        "Importance:\n",
        "\n",
        "1. Identifies relationships.\n",
        "2. Informs feature selection.\n",
        "3. Guides model development.\n",
        "4. Enhances predictive accuracy.\n",
        "\n",
        "Tools:\n",
        "\n",
        "1. Pandas.\n",
        "2. NumPy.\n",
        "3. Matplotlib.\n",
        "4. Seaborn.\n",
        "\n",
        "Example Code:\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Calculate correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Visualize correlation heatmap\n",
        "sns.heatmap(corr_matrix, annot=True)\n"
      ],
      "metadata": {
        "id": "Dqa2dsfeiL5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13. What does negative correlation mean?\n",
        "\n",
        "ANS-> Negative correlation indicates that as one variable increases, the other variable tends to decrease. The relationship is inverse.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "1. As Variable A increases, Variable B decreases.\n",
        "2. As Variable A decreases, Variable B increases.\n",
        "3. The correlation coefficient (r) is between -1 and 0.\n",
        "\n",
        "Examples:\n",
        "\n",
        "1. Temperature and ice cream sales: Higher temperatures lead to lower ice cream sales.\n",
        "2. Stock prices and bond yields: Rising stock prices often accompany falling bond yields.\n",
        "3. Exercise frequency and body fat percentage: Increased exercise tends to reduce body fat.\n",
        "4. Age and reaction time: Older individuals typically have slower reaction times.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "1. Strong negative correlation (r = -0.7 to -1): Very inverse relationship.\n",
        "2. Moderate negative correlation (r = -0.3 to -0.69): Noticeable inverse relationship.\n",
        "3. Weak negative correlation (r = -0.1 to -0.29): Slight inverse relationship.\n",
        "\n",
        "Visual representation:\n",
        "\n",
        "1. Scatter plots: Points slope downward from left to right.\n",
        "2. Line charts: Lines move in opposite directions.\n",
        "\n",
        "Statistics:\n",
        "\n",
        "1. Pearson's r (linear correlation)\n",
        "2. Spearman's ρ (rank correlation)\n",
        "3. Kendall's τ (non-parametric correlation)\n",
        "\n",
        "Code example (Python):\n"
      ],
      "metadata": {
        "id": "iof1aZ8CiblM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data\n",
        "data = {'Temperature': [20, 25, 30, 35, 40],\n",
        "        'Ice Cream Sales': [100, 80, 60, 40, 20]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate correlation\n",
        "correlation = df['Temperature'].corr(df['Ice Cream Sales'])\n",
        "print(correlation)  # Output: -0.99 (strong negative correlation)\n",
        "\n",
        "# Plot scatter plot\n",
        "plt.scatter(df['Temperature'], df['Ice Cream Sales'])\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Ice Cream Sales')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "PPuzaNPui13N",
        "outputId": "8b553c6a-ce7c-4704-d518-350f48e8374c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. How can you find correlation between variables in Python?\n",
        "ANS-> You can find correlation between variables in Python using various libraries and methods:\n",
        "\n",
        "1. Pandas: corr() function\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'A': [1, 2, 3, 4, 5], 'B': [2, 3, 4, 5, 6]})\n",
        "\n",
        "# Calculate correlation\n",
        "correlation = df['A'].corr(df['B'])\n",
        "print(correlation)\n",
        "\n",
        "\n",
        "1. NumPy: corrcoef() function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create arrays\n",
        "A = np.array([1, 2, 3, 4, 5])\n",
        "B = np.array([2, 3, 4, 5, 6])\n",
        "\n",
        "# Calculate correlation\n",
        "correlation = np.corrcoef(A, B)[0, 1]\n",
        "print(correlation)\n",
        "\n",
        "\n",
        "1. SciPy: pearsonr() function\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Create arrays\n",
        "A = np.array([1, 2, 3, 4, 5])\n",
        "B = np.array([2, 3, 4, 5, 6])\n",
        "\n",
        "# Calculate correlation\n",
        "correlation, _ = pearsonr(A, B)\n",
        "print(correlation)\n",
        "\n",
        "\n",
        "1. Matplotlib and Seaborn: Visualize correlation matrices\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'A': [1, 2, 3, 4, 5], 'B': [2, 3, 4, 5, 6]})\n",
        "\n",
        "# Calculate correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Visualize correlation matrix\n",
        "sns.heatmap(corr_matrix, annot=True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3fsMc-s4jDMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "ANS-> Causation:\n",
        "\n",
        "Causation refers to the relationship between an event (cause) and its consequence (effect). In other words, one variable (cause) influences or determines the outcome of another variable (effect).\n",
        "\n",
        "Correlation vs. Causation:\n",
        "\n",
        "Correlation measures the statistical relationship between two variables, whereas causation implies a direct, causal link.\n",
        "\n",
        "Key differences:\n",
        "\n",
        "1. Correlation: Statistical association, not necessarily causal.\n",
        "2. Causation: Direct influence, cause-and-effect relationship.\n",
        "\n",
        "Example:\n",
        "\n",
        "Ice Cream Sales and Temperature\n",
        "\n",
        "Correlation: High positive correlation (0.8) between ice cream sales and temperature.\n",
        "\n",
        "Causation: Does high temperature cause increased ice cream sales?\n",
        "\n",
        "Analysis:\n",
        "\n",
        "1. Common sense: Higher temperatures lead to increased desire for cool treats.\n",
        "2. Experimental design: Conduct experiments controlling for other factors.\n",
        "3. Data analysis: Account for confounding variables (e.g., seasonality).\n",
        "\n",
        "Conclusion: Temperature likely causes increased ice cream sales.\n",
        "\n",
        "Non-Causal Correlation Examples:\n",
        "\n",
        "1. Stock prices and shark attacks: Correlated, but no causal link.\n",
        "2. Coffee consumption and productivity: Correlated, but confounded by morning routine.\n",
        "3. Height and reading ability: Correlated, but no direct causal link.\n",
        "\n",
        "Statistical methods to establish causation:\n",
        "\n",
        "1. Regression analysis\n",
        "2. Instrumental variables\n",
        "3. Propensity score matching\n",
        "4. Randomized controlled trials (RCTs)\n",
        "\n",
        "Tools for causal inference:\n",
        "\n",
        "1. Python libraries: causalml, pycausal\n",
        "2. R packages: causaleffect, Matching\n",
        "\n",
        "Best practices:\n",
        "\n",
        "1. Consider alternative explanations.\n",
        "2. Control for confounding variables.\n",
        "3. Use experimental designs.\n",
        "4. Validate findings with multiple methods.\n"
      ],
      "metadata": {
        "id": "nzDgTOyxja4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "ANS-> Optimizer:\n",
        "\n",
        "An optimizer is an algorithm that adjusts model parameters to minimize the difference between predicted and actual outputs, optimizing model performance.\n",
        "\n",
        "Types of Optimizers:\n",
        "\n",
        "1. Gradient Descent (GD): Updates parameters based on gradient of loss function.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "3G2MqTPyjyDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define loss function\n",
        "def loss(w):\n",
        "    return np.mean((w - 2) ** 2)\n",
        "\n",
        "# Initialize weight\n",
        "w = 0\n",
        "\n",
        "# Learning rate\n",
        "lr = 0.01\n",
        "\n",
        "# Gradient descent\n",
        "for i in range(100):\n",
        "    gradient = 2 * (w - 2)\n",
        "    w -= lr * gradient\n",
        "    print(f\"Iter {i}: Weight {w}, Loss {loss(w)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIS9gjIdkOOf",
        "outputId": "232a2597-5676-4684-cc8b-05a55778f9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0: Weight 0.04, Loss 3.8415999999999997\n",
            "Iter 1: Weight 0.07919999999999999, Loss 3.6894726400000004\n",
            "Iter 2: Weight 0.117616, Loss 3.543369523456\n",
            "Iter 3: Weight 0.15526368000000002, Loss 3.4030520903271424\n",
            "Iter 4: Weight 0.1921584064, Loss 3.2682912275501876\n",
            "Iter 5: Weight 0.228315238272, Loss 3.1388668949392002\n",
            "Iter 6: Weight 0.26374893350656003, Loss 3.0145677658996073\n",
            "Iter 7: Weight 0.29847395483642886, Loss 2.8951908823699832\n",
            "Iter 8: Weight 0.33250447573970027, Loss 2.780541323428132\n",
            "Iter 9: Weight 0.3658543862249063, Loss 2.6704318870203774\n",
            "Iter 10: Weight 0.39853729850040814, Loss 2.564682784294371\n",
            "Iter 11: Weight 0.4305665525304, Loss 2.463121346036314\n",
            "Iter 12: Weight 0.461955221479792, Loss 2.3655817407332758\n",
            "Iter 13: Weight 0.4927161170501962, Loss 2.2719047038002382\n",
            "Iter 14: Weight 0.5228617947091923, Loss 2.1819372775297485\n",
            "Iter 15: Weight 0.5524045588150084, Loss 2.0955325613395703\n",
            "Iter 16: Weight 0.5813564676387082, Loss 2.0125494719105235\n",
            "Iter 17: Weight 0.609729338285934, Loss 1.9328525128228666\n",
            "Iter 18: Weight 0.6375347515202153, Loss 1.8563115533150811\n",
            "Iter 19: Weight 0.664784056489811, Loss 1.782801615803804\n",
            "Iter 20: Weight 0.6914883753600147, Loss 1.7122026718179737\n",
            "Iter 21: Weight 0.7176586078528144, Loss 1.644399446013982\n",
            "Iter 22: Weight 0.7433054356957581, Loss 1.5792812279518287\n",
            "Iter 23: Weight 0.768439326981843, Loss 1.5167416913249359\n",
            "Iter 24: Weight 0.7930705404422062, Loss 1.4566787203484681\n",
            "Iter 25: Weight 0.817209129633362, Loss 1.3989942430226694\n",
            "Iter 26: Weight 0.8408649470406948, Loss 1.3435940709989713\n",
            "Iter 27: Weight 0.8640476480998809, Loss 1.290387745787412\n",
            "Iter 28: Weight 0.8867666951378833, Loss 1.2392883910542303\n",
            "Iter 29: Weight 0.9090313612351256, Loss 1.1902125707684832\n",
            "Iter 30: Weight 0.9308507340104231, Loss 1.143080152966051\n",
            "Iter 31: Weight 0.9522337193302146, Loss 1.0978141789085956\n",
            "Iter 32: Weight 0.9731890449436104, Loss 1.0543407374238152\n",
            "Iter 33: Weight 0.9937252640447382, Loss 1.0125888442218323\n",
            "Iter 34: Weight 1.0138507587638435, Loss 0.9724903259906473\n",
            "Iter 35: Weight 1.0335737435885666, Loss 0.9339797090814177\n",
            "Iter 36: Weight 1.0529022687167953, Loss 0.8969941126017935\n",
            "Iter 37: Weight 1.0718442233424594, Loss 0.8614731457427623\n",
            "Iter 38: Weight 1.0904073388756101, Loss 0.8273588091713491\n",
            "Iter 39: Weight 1.108599192098098, Loss 0.7945954003281637\n",
            "Iter 40: Weight 1.126427208256136, Loss 0.7631294224751685\n",
            "Iter 41: Weight 1.1438986640910132, Loss 0.732909497345152\n",
            "Iter 42: Weight 1.161020690809193, Loss 0.7038862812502839\n",
            "Iter 43: Weight 1.177800276993009, Loss 0.6760123845127728\n",
            "Iter 44: Weight 1.1942442714531487, Loss 0.6492422940860672\n",
            "Iter 45: Weight 1.2103593860240858, Loss 0.6235322992402588\n",
            "Iter 46: Weight 1.2261521983036041, Loss 0.5988404201903444\n",
            "Iter 47: Weight 1.241629154337532, Loss 0.5751263395508069\n",
            "Iter 48: Weight 1.2567965712507814, Loss 0.5523513365045949\n",
            "Iter 49: Weight 1.2716606398257657, Loss 0.530478223579013\n",
            "Iter 50: Weight 1.2862274270292504, Loss 0.509471285925284\n",
            "Iter 51: Weight 1.3005028784886654, Loss 0.4892962230026428\n",
            "Iter 52: Weight 1.3144928209188922, Loss 0.469920092571738\n",
            "Iter 53: Weight 1.3282029645005144, Loss 0.4513112569058971\n",
            "Iter 54: Weight 1.3416389052105042, Loss 0.43343933113242344\n",
            "Iter 55: Weight 1.3548061271062941, Loss 0.4162751336195795\n",
            "Iter 56: Weight 1.3677100045641681, Loss 0.3997906383282443\n",
            "Iter 57: Weight 1.3803558044728848, Loss 0.3839589290504458\n",
            "Iter 58: Weight 1.392748688383427, Loss 0.3687541554600482\n",
            "Iter 59: Weight 1.4048937146157585, Loss 0.35415149090383025\n",
            "Iter 60: Weight 1.4167958403234433, Loss 0.34012709186403867\n",
            "Iter 61: Weight 1.4284599235169744, Loss 0.3266580590262228\n",
            "Iter 62: Weight 1.4398907250466348, Loss 0.3137223998887844\n",
            "Iter 63: Weight 1.4510929105457022, Loss 0.30129899285318845\n",
            "Iter 64: Weight 1.4620710523347882, Loss 0.2893675527362022\n",
            "Iter 65: Weight 1.4728296312880924, Loss 0.2779085976478486\n",
            "Iter 66: Weight 1.4833730386623305, Loss 0.26690341718099386\n",
            "Iter 67: Weight 1.493705577889084, Loss 0.2563340418606264\n",
            "Iter 68: Weight 1.5038314663313024, Loss 0.24618321380294553\n",
            "Iter 69: Weight 1.5137548370046763, Loss 0.23643435853634892\n",
            "Iter 70: Weight 1.5234797402645828, Loss 0.2270715579383095\n",
            "Iter 71: Weight 1.533010145459291, Loss 0.21807952424395252\n",
            "Iter 72: Weight 1.5423499425501053, Loss 0.20944357508389194\n",
            "Iter 73: Weight 1.5515029436991032, Loss 0.20114960951056976\n",
            "Iter 74: Weight 1.5604728848251213, Loss 0.19318408497395112\n",
            "Iter 75: Weight 1.5692634271286188, Loss 0.1855339952089827\n",
            "Iter 76: Weight 1.5778781585860464, Loss 0.178186848998707\n",
            "Iter 77: Weight 1.5863205954143256, Loss 0.17113064977835812\n",
            "Iter 78: Weight 1.594594183506039, Loss 0.1643538760471351\n",
            "Iter 79: Weight 1.6027022998359184, Loss 0.1578454625556685\n",
            "Iter 80: Weight 1.6106482538392, Loss 0.15159478223846407\n",
            "Iter 81: Weight 1.618435288762416, Loss 0.14559162886182084\n",
            "Iter 82: Weight 1.6260665829871677, Loss 0.13982620035889276\n",
            "Iter 83: Weight 1.6335452513274242, Loss 0.13428908282468066\n",
            "Iter 84: Weight 1.6408743463008757, Loss 0.12897123514482337\n",
            "Iter 85: Weight 1.6480568593748581, Loss 0.12386397423308838\n",
            "Iter 86: Weight 1.655095722187361, Loss 0.11895896085345806\n",
            "Iter 87: Weight 1.6619938077436138, Loss 0.11424818600366109\n",
            "Iter 88: Weight 1.6687539315887416, Loss 0.10972395783791605\n",
            "Iter 89: Weight 1.6753788529569669, Loss 0.10537888910753454\n",
            "Iter 90: Weight 1.6818712758978276, Loss 0.10120588509887614\n",
            "Iter 91: Weight 1.688233850379871, Loss 0.09719813204896062\n",
            "Iter 92: Weight 1.6944691733722737, Loss 0.09334908601982178\n",
            "Iter 93: Weight 1.7005797899048283, Loss 0.08965246221343677\n",
            "Iter 94: Weight 1.7065681941067317, Loss 0.08610222470978471\n",
            "Iter 95: Weight 1.712436830224597, Loss 0.0826925766112773\n",
            "Iter 96: Weight 1.718188093620105, Loss 0.07941795057747067\n",
            "Iter 97: Weight 1.7238243317477029, Loss 0.07627299973460287\n",
            "Iter 98: Weight 1.7293478451127489, Loss 0.07325258894511258\n",
            "Iter 99: Weight 1.734760888210494, Loss 0.07035178642288611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Stochastic Gradient Descent (SGD): Updates parameters using single data point.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "u58_4vX8kSsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "# Load iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Create SGD regressor\n",
        "# Changed 'lr' to 'eta0' for learning rate\n",
        "sgd = SGDRegressor(eta0=0.01)\n",
        "\n",
        "# Fit model\n",
        "sgd.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "cihbIETYkXWw",
        "outputId": "d348e5c6-40ed-41f7-f493-202329a19e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SGDRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.SGDRegressor.html\">?<span>Documentation for SGDRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SGDRegressor()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 1. Mini-Batch Gradient Descent (MBGD): Updates parameters using batches.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "rgObGFANks5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(4, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Initialize model, optimizer, and loss\n",
        "model = Net()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Mini-batch gradient descent\n",
        "for batch in range(100):\n",
        "    # Forward pass\n",
        "    outputs = model(torch.randn(32, 4))\n",
        "    labels = torch.randn(32, 3)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "tp5vzJyIkreR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 1. Momentum: Adds momentum term to gradient update.\n",
        "\n",
        "Example:\n"
      ],
      "metadata": {
        "id": "6BoiaBZnk1d3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define model and optimizer\n",
        "model = Net()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train model\n",
        "for batch in range(100):\n",
        "    # Forward pass\n",
        "    outputs = model(torch.randn(32, 4))\n",
        "    labels = torch.randn(32, 3)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "X5GsSsIHkcPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Nesterov Accelerated Gradient (NAG): Modifies momentum update.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "lgb6qHInk8hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g1Ti0CtWlL4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define model and optimizer\n",
        "model = Net()\n",
        "# Use optim.SGD with nesterov=True for NAG\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "# Train model\n",
        "for batch in range(100):\n",
        "    # Forward pass\n",
        "    outputs = model(torch.randn(32, 4))\n",
        "    labels = torch.randn(32, 3)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "bC9vN_EtlMVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Adam: Adaptive learning rate method.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "bfFu_EmvlKSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define model and optimizer\n",
        "model = Net()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Train model\n",
        "for batch in range(100):\n",
        "    # Forward pass\n",
        "    outputs = model(torch.randn(32, 4))\n",
        "    labels = torch.randn(32, 3)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "GyMDviLVlq7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. RMSProp: Normalizes gradient by squared gradient.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "7pkGrh-cluSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define model and optimizer\n",
        "model = Net()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n",
        "\n",
        "# Train model\n",
        "for batch in range(100):\n",
        "    # Forward pass\n",
        "    outputs = model(torch.randn(32, 4))\n",
        "    labels = torch.randn(32, 3)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "8TEcBbx7l1NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17. What is sklearn.linear_model ?\n",
        "\n",
        "ANS-> sklearn.linear_model is a module in scikit-learn, providing implementations of various linear models for regression and classification tasks.\n",
        "\n",
        "Key Features:\n",
        "\n",
        "1. Linear Regression\n",
        "2. Ridge Regression\n",
        "3. Lasso Regression\n",
        "4. Elastic Net Regression\n",
        "5. Logistic Regression\n",
        "6. Support Vector Machines (SVM)\n",
        "7. Stochastic Gradient Descent (SGD)\n",
        "\n",
        "Classes:\n",
        "\n",
        "1. LinearRegression\n",
        "2. Ridge\n",
        "3. Lasso\n",
        "4. ElasticNet\n",
        "5. LogisticRegression\n",
        "6. SGDRegressor\n",
        "7. SGDClassifier\n",
        "8. LinearSVR\n",
        "9. LogisticRegressionCV\n",
        "\n",
        "Methods:\n",
        "\n",
        "1. fit(X, y) - Train model\n",
        "2. predict(X) - Make predictions\n",
        "3. score(X, y) - Evaluate model\n",
        "4. coef_ - Model coefficients\n",
        "5. intercept_ - Model intercept\n",
        "\n",
        "Example Usage:"
      ],
      "metadata": {
        "id": "wx46NiYZmAAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load diabetes dataset\n",
        "diabetes = load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Create and train linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpT32qTCl5ve",
        "outputId": "ae9468fb-8825-45e9-9c41-0f75b3f2c423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3868602704970344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "ANS-> model.fit() is a method in scikit-learn and Keras that trains a machine learning model on a given dataset.\n",
        "\n",
        "Arguments:\n",
        "\n",
        "1. X: Feature matrix (independent variables)\n",
        "2. y: Target vector (dependent variable)\n",
        "3. sample_weight (optional): Weights for individual samples\n",
        "4. batch_size (optional): Number of samples per batch\n",
        "5. epochs (optional): Number of training epochs\n",
        "6. verbose (optional): Verbosity level\n",
        "7. callback (optional): List of callback functions\n",
        "8. validation_data (optional): Validation dataset\n",
        "\n",
        "Scikit-learn fit():\n",
        "\n",
        "1. Trains model on provided data\n",
        "2. Updates model parameters\n",
        "3. Returns trained model\n",
        "\n",
        "Keras fit():\n",
        "\n",
        "1. Trains model on provided data\n",
        "2. Updates model weights\n",
        "3. Returns training history object\n",
        "\n",
        "Example Scikit-learn:"
      ],
      "metadata": {
        "id": "W9XGcdEamaY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "# Load diabetes dataset\n",
        "diabetes = load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Create linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train model\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "GEOv99YimzlP",
        "outputId": "7704db18-7176-4536-b2a2-3708935030be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example Keras:\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Create neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(4,)))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X, y, epochs=100, batch_size=32, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAOrsJ-wm-CG",
        "outputId": "cdbecd62-2e3c-40a0-a3a6-d15cc7a4449d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 - 1s - 247ms/step - accuracy: 0.3333 - loss: 2.6658\n",
            "Epoch 2/100\n",
            "5/5 - 0s - 37ms/step - accuracy: 0.3333 - loss: 2.4956\n",
            "Epoch 3/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.3333 - loss: 2.3420\n",
            "Epoch 4/100\n",
            "5/5 - 0s - 7ms/step - accuracy: 0.3333 - loss: 2.1970\n",
            "Epoch 5/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.3333 - loss: 2.0572\n",
            "Epoch 6/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.3333 - loss: 1.9358\n",
            "Epoch 7/100\n",
            "5/5 - 0s - 7ms/step - accuracy: 0.3333 - loss: 1.8215\n",
            "Epoch 8/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.3333 - loss: 1.7141\n",
            "Epoch 9/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.3333 - loss: 1.6151\n",
            "Epoch 10/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.3333 - loss: 1.5265\n",
            "Epoch 11/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.3333 - loss: 1.4416\n",
            "Epoch 12/100\n",
            "5/5 - 0s - 7ms/step - accuracy: 0.3333 - loss: 1.3615\n",
            "Epoch 13/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.3333 - loss: 1.2849\n",
            "Epoch 14/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.3333 - loss: 1.2162\n",
            "Epoch 15/100\n",
            "5/5 - 0s - 7ms/step - accuracy: 0.3333 - loss: 1.1547\n",
            "Epoch 16/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.3333 - loss: 1.0975\n",
            "Epoch 17/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.3467 - loss: 1.0452\n",
            "Epoch 18/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.5200 - loss: 1.0001\n",
            "Epoch 19/100\n",
            "5/5 - 0s - 7ms/step - accuracy: 0.6200 - loss: 0.9611\n",
            "Epoch 20/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.6667 - loss: 0.9261\n",
            "Epoch 21/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.6667 - loss: 0.8952\n",
            "Epoch 22/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.6667 - loss: 0.8677\n",
            "Epoch 23/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.6600 - loss: 0.8423\n",
            "Epoch 24/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.6800 - loss: 0.8196\n",
            "Epoch 25/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.7933 - loss: 0.7995\n",
            "Epoch 26/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.8467 - loss: 0.7808\n",
            "Epoch 27/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.8533 - loss: 0.7635\n",
            "Epoch 28/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.8600 - loss: 0.7473\n",
            "Epoch 29/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.8667 - loss: 0.7323\n",
            "Epoch 30/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.8800 - loss: 0.7183\n",
            "Epoch 31/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.9067 - loss: 0.7048\n",
            "Epoch 32/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.9067 - loss: 0.6919\n",
            "Epoch 33/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9133 - loss: 0.6797\n",
            "Epoch 34/100\n",
            "5/5 - 0s - 7ms/step - accuracy: 0.9133 - loss: 0.6680\n",
            "Epoch 35/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9067 - loss: 0.6567\n",
            "Epoch 36/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9133 - loss: 0.6459\n",
            "Epoch 37/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.9133 - loss: 0.6356\n",
            "Epoch 38/100\n",
            "5/5 - 0s - 7ms/step - accuracy: 0.9133 - loss: 0.6256\n",
            "Epoch 39/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.9133 - loss: 0.6160\n",
            "Epoch 40/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.9133 - loss: 0.6067\n",
            "Epoch 41/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.9133 - loss: 0.5977\n",
            "Epoch 42/100\n",
            "5/5 - 0s - 7ms/step - accuracy: 0.9133 - loss: 0.5892\n",
            "Epoch 43/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9133 - loss: 0.5807\n",
            "Epoch 44/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9133 - loss: 0.5727\n",
            "Epoch 45/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9133 - loss: 0.5649\n",
            "Epoch 46/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9267 - loss: 0.5574\n",
            "Epoch 47/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.9200 - loss: 0.5501\n",
            "Epoch 48/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9333 - loss: 0.5429\n",
            "Epoch 49/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.9133 - loss: 0.5361\n",
            "Epoch 50/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.9200 - loss: 0.5294\n",
            "Epoch 51/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9467 - loss: 0.5231\n",
            "Epoch 52/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9533 - loss: 0.5168\n",
            "Epoch 53/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9533 - loss: 0.5109\n",
            "Epoch 54/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9600 - loss: 0.5056\n",
            "Epoch 55/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9600 - loss: 0.4994\n",
            "Epoch 56/100\n",
            "5/5 - 0s - 26ms/step - accuracy: 0.9533 - loss: 0.4940\n",
            "Epoch 57/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9533 - loss: 0.4883\n",
            "Epoch 58/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9533 - loss: 0.4837\n",
            "Epoch 59/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.9533 - loss: 0.4783\n",
            "Epoch 60/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9533 - loss: 0.4732\n",
            "Epoch 61/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9533 - loss: 0.4684\n",
            "Epoch 62/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9533 - loss: 0.4637\n",
            "Epoch 63/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9600 - loss: 0.4593\n",
            "Epoch 64/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.4544\n",
            "Epoch 65/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9600 - loss: 0.4503\n",
            "Epoch 66/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.9600 - loss: 0.4458\n",
            "Epoch 67/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9600 - loss: 0.4418\n",
            "Epoch 68/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.9600 - loss: 0.4379\n",
            "Epoch 69/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.9600 - loss: 0.4338\n",
            "Epoch 70/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9600 - loss: 0.4303\n",
            "Epoch 71/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9533 - loss: 0.4265\n",
            "Epoch 72/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9600 - loss: 0.4227\n",
            "Epoch 73/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.9667 - loss: 0.4197\n",
            "Epoch 74/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9733 - loss: 0.4158\n",
            "Epoch 75/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9733 - loss: 0.4123\n",
            "Epoch 76/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9733 - loss: 0.4091\n",
            "Epoch 77/100\n",
            "5/5 - 0s - 27ms/step - accuracy: 0.9667 - loss: 0.4058\n",
            "Epoch 78/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.9600 - loss: 0.4029\n",
            "Epoch 79/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9600 - loss: 0.3996\n",
            "Epoch 80/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9667 - loss: 0.3965\n",
            "Epoch 81/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9667 - loss: 0.3938\n",
            "Epoch 82/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9733 - loss: 0.3906\n",
            "Epoch 83/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9733 - loss: 0.3878\n",
            "Epoch 84/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9733 - loss: 0.3850\n",
            "Epoch 85/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.9733 - loss: 0.3822\n",
            "Epoch 86/100\n",
            "5/5 - 0s - 27ms/step - accuracy: 0.9733 - loss: 0.3794\n",
            "Epoch 87/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.9733 - loss: 0.3770\n",
            "Epoch 88/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9733 - loss: 0.3741\n",
            "Epoch 89/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.9733 - loss: 0.3713\n",
            "Epoch 90/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9733 - loss: 0.3690\n",
            "Epoch 91/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9800 - loss: 0.3668\n",
            "Epoch 92/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.9733 - loss: 0.3642\n",
            "Epoch 93/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.9733 - loss: 0.3618\n",
            "Epoch 94/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9733 - loss: 0.3592\n",
            "Epoch 95/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9733 - loss: 0.3573\n",
            "Epoch 96/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9733 - loss: 0.3544\n",
            "Epoch 97/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9733 - loss: 0.3527\n",
            "Epoch 98/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9733 - loss: 0.3498\n",
            "Epoch 99/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9733 - loss: 0.3477\n",
            "Epoch 100/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9733 - loss: 0.3459\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7819f66ff9a0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "ANS-> model.predict() is a method in scikit-learn and Keras that uses a trained machine learning model to make predictions on new, unseen data.\n",
        "\n",
        "Arguments:\n",
        "\n",
        "1. X: Feature matrix (independent variables) for which predictions are to be made\n",
        "2. batch_size (optional): Number of samples per batch\n",
        "3. verbose (optional): Verbosity level\n",
        "\n",
        "Return Value:\n",
        "\n",
        "1. Predicted target values (y_pred)\n",
        "\n",
        "Scikit-learn predict():\n",
        "\n",
        "1. Returns predicted values\n",
        "2. Does not modify original model\n",
        "\n",
        "Keras predict():\n",
        "\n",
        "1. Returns predicted values\n",
        "2. Does not modify original model\n",
        "3. Supports batch processing\n",
        "\n",
        "Example Scikit-learn:"
      ],
      "metadata": {
        "id": "qow7FKPqnebv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "# Load diabetes dataset\n",
        "diabetes = load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Create and train linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "X_new = [[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]]\n",
        "y_pred = model.predict(X_new)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_4ct1-6n1i_",
        "outputId": "b0fe8a0d-77b5-4237-c492-1785450c10c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1234.98649582]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example Keras:\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Create and train neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(4,)))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=100, batch_size=32, verbose=2)\n",
        "\n",
        "# Make predictions\n",
        "X_new = [[5.1, 3.5, 1.4, 0.2]]\n",
        "y_pred = model.predict(X_new)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yUpSffMEn6Lf",
        "outputId": "18173cba-17a4-43e4-ccbf-8a6b476f80df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 - 2s - 385ms/step - accuracy: 0.0000e+00 - loss: 2.0866\n",
            "Epoch 2/100\n",
            "5/5 - 0s - 29ms/step - accuracy: 0.0000e+00 - loss: 1.9645\n",
            "Epoch 3/100\n",
            "5/5 - 0s - 26ms/step - accuracy: 0.0000e+00 - loss: 1.8536\n",
            "Epoch 4/100\n",
            "5/5 - 0s - 33ms/step - accuracy: 0.0067 - loss: 1.7508\n",
            "Epoch 5/100\n",
            "5/5 - 0s - 22ms/step - accuracy: 0.0067 - loss: 1.6525\n",
            "Epoch 6/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.0067 - loss: 1.5678\n",
            "Epoch 7/100\n",
            "5/5 - 0s - 32ms/step - accuracy: 0.0067 - loss: 1.4936\n",
            "Epoch 8/100\n",
            "5/5 - 0s - 27ms/step - accuracy: 0.0133 - loss: 1.4361\n",
            "Epoch 9/100\n",
            "5/5 - 0s - 59ms/step - accuracy: 0.0133 - loss: 1.3885\n",
            "Epoch 10/100\n",
            "5/5 - 0s - 53ms/step - accuracy: 0.0267 - loss: 1.3544\n",
            "Epoch 11/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.1067 - loss: 1.3240\n",
            "Epoch 12/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.2200 - loss: 1.3009\n",
            "Epoch 13/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.2467 - loss: 1.2796\n",
            "Epoch 14/100\n",
            "5/5 - 0s - 31ms/step - accuracy: 0.2667 - loss: 1.2584\n",
            "Epoch 15/100\n",
            "5/5 - 0s - 24ms/step - accuracy: 0.2733 - loss: 1.2367\n",
            "Epoch 16/100\n",
            "5/5 - 0s - 27ms/step - accuracy: 0.2867 - loss: 1.2165\n",
            "Epoch 17/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.3000 - loss: 1.1966\n",
            "Epoch 18/100\n",
            "5/5 - 0s - 14ms/step - accuracy: 0.3000 - loss: 1.1770\n",
            "Epoch 19/100\n",
            "5/5 - 0s - 21ms/step - accuracy: 0.3000 - loss: 1.1578\n",
            "Epoch 20/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.3200 - loss: 1.1379\n",
            "Epoch 21/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.3267 - loss: 1.1201\n",
            "Epoch 22/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.3333 - loss: 1.1009\n",
            "Epoch 23/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.3400 - loss: 1.0824\n",
            "Epoch 24/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.3400 - loss: 1.0641\n",
            "Epoch 25/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.3533 - loss: 1.0462\n",
            "Epoch 26/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.3533 - loss: 1.0288\n",
            "Epoch 27/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.3467 - loss: 1.0101\n",
            "Epoch 28/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.3467 - loss: 0.9938\n",
            "Epoch 29/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.3600 - loss: 0.9756\n",
            "Epoch 30/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.3800 - loss: 0.9596\n",
            "Epoch 31/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.4467 - loss: 0.9415\n",
            "Epoch 32/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.4800 - loss: 0.9259\n",
            "Epoch 33/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.5467 - loss: 0.9091\n",
            "Epoch 34/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.6000 - loss: 0.8933\n",
            "Epoch 35/100\n",
            "5/5 - 0s - 28ms/step - accuracy: 0.6533 - loss: 0.8772\n",
            "Epoch 36/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.6867 - loss: 0.8620\n",
            "Epoch 37/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.7467 - loss: 0.8476\n",
            "Epoch 38/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.7667 - loss: 0.8334\n",
            "Epoch 39/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.8067 - loss: 0.8186\n",
            "Epoch 40/100\n",
            "5/5 - 0s - 13ms/step - accuracy: 0.8200 - loss: 0.8043\n",
            "Epoch 41/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.8133 - loss: 0.7906\n",
            "Epoch 42/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.8067 - loss: 0.7766\n",
            "Epoch 43/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.8067 - loss: 0.7636\n",
            "Epoch 44/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.8067 - loss: 0.7508\n",
            "Epoch 45/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.8067 - loss: 0.7383\n",
            "Epoch 46/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.8067 - loss: 0.7268\n",
            "Epoch 47/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.8267 - loss: 0.7147\n",
            "Epoch 48/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.8333 - loss: 0.7035\n",
            "Epoch 49/100\n",
            "5/5 - 0s - 29ms/step - accuracy: 0.8200 - loss: 0.6922\n",
            "Epoch 50/100\n",
            "5/5 - 0s - 20ms/step - accuracy: 0.8667 - loss: 0.6810\n",
            "Epoch 51/100\n",
            "5/5 - 0s - 29ms/step - accuracy: 0.8733 - loss: 0.6700\n",
            "Epoch 52/100\n",
            "5/5 - 0s - 29ms/step - accuracy: 0.8733 - loss: 0.6597\n",
            "Epoch 53/100\n",
            "5/5 - 0s - 16ms/step - accuracy: 0.8667 - loss: 0.6508\n",
            "Epoch 54/100\n",
            "5/5 - 0s - 33ms/step - accuracy: 0.8800 - loss: 0.6395\n",
            "Epoch 55/100\n",
            "5/5 - 0s - 23ms/step - accuracy: 0.8733 - loss: 0.6314\n",
            "Epoch 56/100\n",
            "5/5 - 0s - 29ms/step - accuracy: 0.8733 - loss: 0.6214\n",
            "Epoch 57/100\n",
            "5/5 - 0s - 28ms/step - accuracy: 0.8733 - loss: 0.6125\n",
            "Epoch 58/100\n",
            "5/5 - 0s - 30ms/step - accuracy: 0.8800 - loss: 0.6040\n",
            "Epoch 59/100\n",
            "5/5 - 0s - 19ms/step - accuracy: 0.8800 - loss: 0.5969\n",
            "Epoch 60/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9267 - loss: 0.5870\n",
            "Epoch 61/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9067 - loss: 0.5794\n",
            "Epoch 62/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.8933 - loss: 0.5708\n",
            "Epoch 63/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.8933 - loss: 0.5639\n",
            "Epoch 64/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9067 - loss: 0.5557\n",
            "Epoch 65/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.9000 - loss: 0.5478\n",
            "Epoch 66/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9000 - loss: 0.5410\n",
            "Epoch 67/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9067 - loss: 0.5339\n",
            "Epoch 68/100\n",
            "5/5 - 0s - 28ms/step - accuracy: 0.9067 - loss: 0.5271\n",
            "Epoch 69/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9133 - loss: 0.5210\n",
            "Epoch 70/100\n",
            "5/5 - 0s - 13ms/step - accuracy: 0.9200 - loss: 0.5140\n",
            "Epoch 71/100\n",
            "5/5 - 0s - 25ms/step - accuracy: 0.9333 - loss: 0.5073\n",
            "Epoch 72/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.9333 - loss: 0.5013\n",
            "Epoch 73/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9333 - loss: 0.4961\n",
            "Epoch 74/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9400 - loss: 0.4892\n",
            "Epoch 75/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9267 - loss: 0.4860\n",
            "Epoch 76/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9200 - loss: 0.4784\n",
            "Epoch 77/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9333 - loss: 0.4729\n",
            "Epoch 78/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.9400 - loss: 0.4679\n",
            "Epoch 79/100\n",
            "5/5 - 0s - 27ms/step - accuracy: 0.9400 - loss: 0.4623\n",
            "Epoch 80/100\n",
            "5/5 - 0s - 16ms/step - accuracy: 0.9400 - loss: 0.4570\n",
            "Epoch 81/100\n",
            "5/5 - 0s - 26ms/step - accuracy: 0.9400 - loss: 0.4527\n",
            "Epoch 82/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.9333 - loss: 0.4485\n",
            "Epoch 83/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9400 - loss: 0.4429\n",
            "Epoch 84/100\n",
            "5/5 - 0s - 6ms/step - accuracy: 0.9333 - loss: 0.4376\n",
            "Epoch 85/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9400 - loss: 0.4335\n",
            "Epoch 86/100\n",
            "5/5 - 0s - 7ms/step - accuracy: 0.9400 - loss: 0.4291\n",
            "Epoch 87/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.4248\n",
            "Epoch 88/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9400 - loss: 0.4204\n",
            "Epoch 89/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9400 - loss: 0.4164\n",
            "Epoch 90/100\n",
            "5/5 - 0s - 13ms/step - accuracy: 0.9400 - loss: 0.4123\n",
            "Epoch 91/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9400 - loss: 0.4081\n",
            "Epoch 92/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9400 - loss: 0.4044\n",
            "Epoch 93/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9400 - loss: 0.4009\n",
            "Epoch 94/100\n",
            "5/5 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.3987\n",
            "Epoch 95/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9400 - loss: 0.3934\n",
            "Epoch 96/100\n",
            "5/5 - 0s - 12ms/step - accuracy: 0.9400 - loss: 0.3898\n",
            "Epoch 97/100\n",
            "5/5 - 0s - 10ms/step - accuracy: 0.9467 - loss: 0.3870\n",
            "Epoch 98/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9400 - loss: 0.3828\n",
            "Epoch 99/100\n",
            "5/5 - 0s - 9ms/step - accuracy: 0.9333 - loss: 0.3807\n",
            "Epoch 100/100\n",
            "5/5 - 0s - 11ms/step - accuracy: 0.9333 - loss: 0.3755\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized data type: x=[[5.1, 3.5, 1.4, 0.2]] (of type <class 'list'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2afb342133d2>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized data type: x={x} (of type {type(x)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=[[5.1, 3.5, 1.4, 0.2]] (of type <class 'list'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20. What are continuous and categorical variables?\n",
        "\n",
        "ANS-> In statistics and machine learning, variables are classified into two primary types:\n",
        "\n",
        "1. Continuous Variables:\n",
        "\n",
        "Definition: Variables that can take any value within a range or interval, including fractions and decimals.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "1. Measurable\n",
        "2. Quantifiable\n",
        "3. Can be expressed as real numbers\n",
        "4. No natural categories or boundaries\n",
        "\n",
        "Examples:\n",
        "\n",
        "1. Age (18.5, 25.2, 30.8)\n",
        "2. Height (165.2 cm, 175.5 cm, 180.8 cm)\n",
        "3. Weight (65.1 kg, 72.3 kg, 80.5 kg)\n",
        "4. Temperature (23.4°C, 25.6°C, 30.2°C)\n",
        "5. Income ($50,000, $75,000, $100,000)\n",
        "6. Categorical Variables:\n",
        "\n",
        "Definition: Variables that represent distinct categories or groups.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "1. Non-numerical\n",
        "2. Qualitative\n",
        "3. Nominal or ordinal\n",
        "4. Limited number of distinct values\n",
        "\n",
        "Types of Categorical Variables:\n",
        "\n",
        "1. Nominal: No inherent order (e.g., colors: red, blue, green)\n",
        "2. Ordinal: Ordered categories (e.g., education level: high school, bachelor's, master's)\n",
        "\n",
        "Examples:\n",
        "\n",
        "1. Gender (male, female, other)\n",
        "2. Country (USA, Canada, UK)\n",
        "3. Occupation (student, engineer, doctor)\n",
        "4. Color (red, blue, green)\n",
        "5. Product category (electronics, clothing, home goods)\n",
        "\n",
        "Importance:\n",
        "\n",
        "1. Data analysis and visualization\n",
        "2. Machine learning algorithm selection\n",
        "3. Feature engineering and preprocessing\n",
        "4. Model interpretation and evaluation\n",
        "\n",
        "Common techniques for categorical variables:\n",
        "\n",
        "1. One-hot encoding\n",
        "2. Label encoding\n",
        "3. Ordinal encoding\n",
        "4. Dummy variables\n",
        "\n",
        "Common techniques for continuous variables:\n",
        "\n",
        "1. Normalization\n",
        "2. Standardization\n",
        "3. Scaling\n",
        "4. Log transformation\n",
        "\n",
        "Understanding variable types is crucial for:\n",
        "\n",
        "1. Data preprocessing\n",
        "2. Model selection\n",
        "3. Feature engineering\n",
        "4. Data visualization\n",
        "5. Statistical analysis"
      ],
      "metadata": {
        "id": "jP75ucg1n_e_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "ANS-> Feature scaling, also known as normalization or standardization, is a technique used in machine learning to transform numeric data into a common range, usually between 0 and 1, or with a mean of 0 and standard deviation of 1.\n",
        "\n",
        "Why Feature Scaling?\n",
        "\n",
        "1. Prevents feature dominance: Ensures no single feature dominates model\n",
        "2. Improves convergence: Faster and more stable convergence\n",
        "3. Enhances model performance: Better accuracy and generalization\n",
        "4. Supports algorithm requirements: Some algorithms require scaled data\n",
        "\n",
        "Types of Feature Scaling:\n",
        "\n",
        "1. Min-Max Scaling (Normalization): Rescales data between 0 and 1.\n",
        "2. Standardization: Scales data to mean 0 and standard deviation 1.\n",
        "3. Log Scaling: Transforms skewed data into a more symmetric distribution.\n",
        "4. L1/L2 Normalization: Scales data using L1 or L2 norm.\n",
        "\n",
        "Benefits:\n",
        "\n",
        "1. Improved model interpretability\n",
        "2. Enhanced model robustness\n",
        "3. Faster training times\n",
        "4. Better handling of outliers\n",
        "5. Supports multiple algorithms\n",
        "\n",
        "Algorithms Requiring Feature Scaling:\n",
        "\n",
        "1. K-Means\n",
        "2. K-Nearest Neighbors (KNN)\n",
        "3. Support Vector Machines (SVM)\n",
        "4. Neural Networks\n",
        "5. Gradient Boosting\n",
        "\n",
        "Python Libraries:\n",
        "\n",
        "1. scikit-learn: StandardScaler, MinMaxScaler\n",
        "2. TensorFlow: tf.keras.layers.Normalization\n",
        "3. PyTorch: torch.nn.functional.normalize\n",
        "\n",
        "Example Code (scikit-learn):"
      ],
      "metadata": {
        "id": "tOb1rph8oO2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Create scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform data\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(scaled_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnVAxu_Zoeqf",
        "outputId": "ea54c476-8258-4209-8064-d98c468c2440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.22474487 -1.22474487]\n",
            " [ 0.          0.        ]\n",
            " [ 1.22474487  1.22474487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22. How do we perform scaling in Python?\n",
        "\n",
        "ANS-> Scaling in Python can be performed using various libraries and techniques. Here are some common methods:\n",
        "\n",
        "Popular Libraries:\n",
        "\n",
        "1. scikit-learn\n",
        "2. scipy\n",
        "3. numpy\n",
        "4. pandas\n",
        "5. TensorFlow\n",
        "6. PyTorch\n",
        "\n",
        "Techniques:\n",
        "\n",
        "1. Standardization\n",
        "2. Normalization\n",
        "3. Min-Max Scaling\n",
        "4. Log Scaling\n",
        "5. L1/L2 Normalization\n",
        "\n",
        "Choosing Scaling Method:\n",
        "\n",
        "1. Data distribution\n",
        "2. Algorithm requirements\n",
        "3. Model performance\n",
        "4. Interpretability\n",
        "\n",
        "1. StandardScaler (sklearn):"
      ],
      "metadata": {
        "id": "yMlVDF1CojPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Create scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform data\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5JAi9umoiLg",
        "outputId": "f305e9a8-7a53-4f52-e6cc-993989872014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.22474487 -1.22474487]\n",
            " [ 0.          0.        ]\n",
            " [ 1.22474487  1.22474487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UTYpIchLpGzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. MinMaxScaler (sklearn):\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Create scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform data\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(scaled_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M39Wa4ZQpHCX",
        "outputId": "f5a95a8c-b97c-4eef-e58e-e769e1034e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0. ]\n",
            " [0.5 0.5]\n",
            " [1.  1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Normalization (sklearn):\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Create scaler\n",
        "scaler = Normalizer()\n",
        "\n",
        "# Fit and transform data\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2nkAHhmpHIh",
        "outputId": "41cb064d-f717-457e-eaa9-84296d6267b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.4472136  0.89442719]\n",
            " [0.6        0.8       ]\n",
            " [0.6401844  0.76822128]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Log Scaling (numpy):\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Log scale data\n",
        "scaled_data = np.log(data)\n",
        "\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXg69aTopSBY",
        "outputId": "390fbc00-36cc-438a-c30d-79eccaaaafcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.69314718]\n",
            " [1.09861229 1.38629436]\n",
            " [1.60943791 1.79175947]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. L1/L2 Normalization (scipy):\n",
        "\n",
        "from scipy.linalg import norm\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# L1 normalize\n",
        "scaled_data = data / norm(data, 1)\n",
        "\n",
        "print(scaled_data)\n",
        "\n",
        "# L2 normalize\n",
        "scaled_data = data / norm(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU4SQcj9pSV_",
        "outputId": "3baadbd3-8811-40f9-a9f4-e58355eb1c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.08333333 0.16666667]\n",
            " [0.25       0.33333333]\n",
            " [0.41666667 0.5       ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23. What is sklearn.preprocessing?\n",
        "\n",
        "ANS-> sklearn.preprocessing is a module in scikit-learn library that provides various techniques for data preprocessing, including:\n",
        "\n",
        "1. Scaling and normalization\n",
        "2. Encoding categorical variables\n",
        "3. Handling missing values\n",
        "4. Feature selection and transformation\n",
        "5. Data normalization and standardization\n",
        "\n",
        "Submodules:\n",
        "\n",
        "1. sklearn.preprocessing.data\n",
        "2. sklearn.preprocessing.feature\n",
        "3. sklearn.preprocessing.feature_selection\n",
        "4. sklearn.preprocessing.label\n",
        "5. sklearn.preprocessing.multiclass\n",
        "6. sklearn.preprocessing.text\n",
        "\n",
        "Classes:\n",
        "\n",
        "1. StandardScaler\n",
        "2. MinMaxScaler\n",
        "3. Normalizer\n",
        "4. OneHotEncoder\n",
        "5. LabelEncoder\n",
        "6. Imputer\n",
        "7. PolynomialFeatures\n",
        "8. Binarizer\n",
        "\n",
        "Functions:\n",
        "\n",
        "1. scale()\n",
        "2. normalize()\n",
        "3. fit_transform()\n",
        "4. transform()\n",
        "\n",
        "Purpose:\n",
        "\n",
        "1. Prepare data for machine learning algorithms\n",
        "2. Improve model performance and stability\n",
        "3. Handle different data types and formats\n",
        "4. Reduce dimensionality and complexity\n",
        "\n",
        "Common Use Cases:\n",
        "\n",
        "1. Data preprocessing for classification and regression\n",
        "2. Feature engineering and selection\n",
        "3. Handling categorical and numerical data\n",
        "4. Preprocessing text and image data\n",
        "5. Normalizing and standardizing data\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "NaH_am0rps4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Create scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform data\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(scaled_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI1gQpTZpaXQ",
        "outputId": "b0187570-e28a-4a83-fb68-e295774863e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.22474487 -1.22474487]\n",
            " [ 0.          0.        ]\n",
            " [ 1.22474487  1.22474487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "ANS-> In Python, you can split data for model fitting (training and testing) using the train_test_split function from the sklearn.model_selection module.\n",
        "\n",
        "Basic Syntax:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "Parameters:\n",
        "\n",
        "1. X: Feature matrix (independent variables)\n",
        "2. y: Target vector (dependent variable)\n",
        "3. test_size: Proportion of data for testing (default=0.25)\n",
        "4. random_state: Seed for random splitting (default=None)\n",
        "5. shuffle: Whether to shuffle data before splitting (default=True)\n",
        "6. stratify: Whether to stratify split based on target variable (default=None)\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "Rp1qBR-sqGEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KhRuIRRpabU",
        "outputId": "e57bb5ec-3d75-4a86-9fb2-b482af3ffd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (120, 4) (120,)\n",
            "Testing set: (30, 4) (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25. Explain data encoding?\n",
        "\n",
        "ANS-> Data encoding is the process of converting categorical or text data into numerical representations that can be processed by machine learning algorithms.\n",
        "\n",
        "Types of Encoding:\n",
        "\n",
        "1. Label Encoding: Assigns a unique integer value to each category.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "tiqXBSvGvqZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "data = ['red', 'green', 'blue', 'red', 'green']\n",
        "encoded_data = le.fit_transform(data)\n",
        "print(encoded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAlFk2d-pah9",
        "outputId": "d51a6c2b-ded0-46fb-ff95-c04e423b4096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 1 0 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. One-Hot Encoding (OHE): Creates binary columns for each category.\n",
        "\n",
        "Example:\n"
      ],
      "metadata": {
        "id": "UazHN5dowW80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "data = [['red'], ['green'], ['blue'], ['red'], ['green']]\n",
        "encoded_data = ohe.fit_transform(data)\n",
        "print(encoded_data.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0b5G_jxwZos",
        "outputId": "3b0b9a1e-c20c-410a-9170-54eda94b89e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Ordinal Encoding: Assigns ordered integer values to categories.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "dMGViLXuwaBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "oe = OrdinalEncoder()\n",
        "data = [['low'], ['medium'], ['high'], ['low'], ['medium']]\n",
        "encoded_data = oe.fit_transform(data)\n",
        "print(encoded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piQf3vCPwaNh",
        "outputId": "e5f336e6-37ee-4032-b196-b7550bc6521a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]\n",
            " [2.]\n",
            " [0.]\n",
            " [1.]\n",
            " [2.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Binary Encoding: Represents text data as binary vectors.\n",
        "\n",
        "Example:\n"
      ],
      "metadata": {
        "id": "WfmVMUqJwaVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "data = ['hello world', 'hello', 'world']\n",
        "encoded_data = cv.fit_transform(data)\n",
        "print(encoded_data.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTZaJ5rpwaf8",
        "outputId": "781c799d-98a8-4f58-b24a-1521d1b03551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1]\n",
            " [1 0]\n",
            " [0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Hashing Encoding: Uses hash functions to encode text data.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "qFN-AdDnwrft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "hv = HashingVectorizer()\n",
        "data = ['hello world', 'hello', 'world']\n",
        "encoded_data = hv.fit_transform(data)\n",
        "print(encoded_data.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqJNUEyFwqZn",
        "outputId": "0bd83a52-43ca-46f0-ee30-25d4435ca817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    }
  ]
}